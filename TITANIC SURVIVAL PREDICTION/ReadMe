# Titanic Survival Prediction

## **Description**

This project focuses on building a machine learning model to predict whether a passenger survived the Titanic disaster. Using the **Titanic dataset**, various classification algorithms such as **Logistic Regression**, **Decision Trees**, **Random Forest**, **K-Nearest Neighbors**, and **Support Vector Machine** are applied to build predictive models. The project demonstrates the process of data preprocessing, feature engineering, model training, and evaluation.

The dataset contains information about the passengers, including personal details and the class of ticket they held. We used this data to train machine learning models to predict survival rates, focusing on **data science** techniques like feature scaling, model evaluation, and classification performance analysis.

---

## **Table of Contents**

1. [Project Overview](#overview)
2. [Dataset](#dataset)
3. [Data Preprocessing](#data-preprocessing)
4. [Machine Learning Models](#machine-learning-models)
5. [Model Performance](#model-performance)
6. [Installation](#installation)
7. [Usage](#usage)
8. [Contributing](#contributing)

---

## **Dataset**

The Titanic dataset used in this project is sourced from Kaggle. You can download it from [here](https://www.kaggle.com/datasets/yasserh/titanic-dataset).

Key columns in the dataset include:

- **Survived**: The target variable (1 = survived, 0 = did not survive)
- **Pclass**: Passenger class (1, 2, 3)
- **Name**: Name of the passenger
- **Sex**: Gender of the passenger
- **Age**: Age of the passenger
- **SibSp**: Number of siblings or spouses aboard the Titanic
- **Parch**: Number of parents or children aboard the Titanic
- **Ticket**: Ticket number
- **Fare**: Fare paid by the passenger
- **Embarked**: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)

---

## **Data Preprocessing**

Before building the models, we perform several steps to prepare the data:

- **Handling Missing Values**: 
  - Missing values in the 'Age' column are filled with the median.
  - Missing 'Embarked' values are filled with the most frequent value.

- **Feature Engineering**:
  - Created a new feature: **FamilySize** (combining 'SibSp' and 'Parch').

- **Encoding Categorical Features**:
  - Converted **Sex** and **Embarked** to numeric values using label encoding.

- **Feature Scaling**:
  - Scaled numerical features like **Age** and **Fare** using standardization techniques to improve model performance.

---

## **Machine Learning Models**

We tested the following classification models to predict Titanic survival:

- **Logistic Regression**
- **Decision Tree Classifier**
- **Random Forest Classifier**
- **K-Nearest Neighbors (KNN)**
- **Support Vector Machine (SVM)**

Each model was trained on the preprocessed data and evaluated using various performance metrics.

---

## **Model Performance**

The following table summarizes the performance of each model on the Titanic dataset. The evaluation metrics include **Accuracy**, **Precision**, **Recall**, and **F1-Score**, which are standard metrics used to assess classification models.

| Model                   | Accuracy (%) | Precision (%) | Recall (%) | F1-Score (%) |
|-------------------------|--------------|---------------|------------|--------------|
| Logistic Regression      | 81.5         | 81.3          | 99.7       | 93.5         |
| Decision Tree Classifier | 82.0         | 92.5          | 90.3       | 91.4         |
| Random Forest Classifier | 93.2         | 83.0          | 81.2       | 91.1         |
| K-Nearest Neighbors      | 88.5         | 87.9          | 85.0       | 92.4         |
| Support Vector Machine   | 80.5         | 80.3          | 88.2       | 90.2         |

As shown in the table, the **Random Forest Classifier** outperforms other models with the highest accuracy, precision, recall, and F1-score. This demonstrates the value of ensemble learning techniques in this data science task.

---

## **Installation**

To run this project on your local machine, follow these steps:

1. Clone the repository:

    ```bash
    git clone https://github.com/Chandrashekar0123/CODSOFT/edit/main/TITANIC%20SURVIVAL%20PREDICTION
    ```

2. Navigate to the project directory:

    ```bash
    cd titanic-survival-prediction
    ```

3. Install the required dependencies:

    ```bash
    pip install -r requirements.txt
    ```

---

## **Usage**

Once the required libraries are installed, you can run the project by executing the following command:

    ```bash
    python titanic_model.py
    ```

This will:
- Load and preprocess the data.
- Train the machine learning models.
- Output the performance metrics for each model.

---

## **Contributing**

Feel free to fork the repository, contribute improvements, or suggest new features. All contributions are welcome!

- **GitHub**: [Chandrashekar0123](https://github.com/Chandrashekar0123/CODSOFT)
- **LinkedIn**: [Chandra Shekar](https://www.linkedin.com/in/k-chandra-shekar-reddy-344793287/)

---


### **Summary**

This project showcases the power of **Data Science** techniques in solving classification problems. By leveraging machine learning models and comprehensive data preprocessing, we built models that predict Titanic survival with a high degree of accuracy. This project is a great example of how data science can be applied to real-world challenges, with each step involving important techniques like feature engineering, model training, and performance evaluation.

---

